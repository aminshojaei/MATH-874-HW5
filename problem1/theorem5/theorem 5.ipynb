{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Theorem 5\n",
    "\n",
    "#### Submitted by Amin Shojaeighadikolaei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot(X):   \n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    temp = X.reshape(len(X), 1)\n",
    "    onehots = onehot_encoder.fit_transform(temp)\n",
    "    return(onehots)\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    return ((data - data.mean()) / np.sqrt(np.var(data)))\n",
    "\n",
    "def sigmoid(data):\n",
    "    return 1 / (1 + np.exp(-data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "output_size = 6\n",
    "hidden_layers = [4, 3]\n",
    "nSamples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly pick joint distribution, normalize\n",
    "Pxy = np.random.random([output_size, input_size])\n",
    "Pxy = Pxy / np.sum(np.sum(Pxy,axis=0),axis=0)\n",
    "#  # compute marginals\n",
    "Px = np.sum(Pxy, axis = 0)\n",
    "Py = np.sum(Pxy, axis = 1)\n",
    "\n",
    "X=np.random.choice(range(input_size),nSamples,p=Px)\n",
    "Y=np.random.choice(range(output_size),nSamples,p=Py)\n",
    "\n",
    "x_train = One_hot(X)\n",
    "y_train = One_hot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_layers[0], activation='sigmoid', input_dim=input_size))\n",
    "model.add(Dense(hidden_layers[1], activation='softmax', input_dim=hidden_layers[0]))    \n",
    "model.add(Dense(output_size, activation='softmax', input_dim=hidden_layers[1]))\n",
    "\n",
    "sgd = SGD(lr=4, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=.01) \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = (Pxy- Px.reshape(1, -1)*Py.reshape(-1, 1))/ np.sqrt(Px.reshape(1, -1)) * np.sqrt(Py.reshape(-1, 1))\n",
    "phi_y, phi, phi_x = np.linalg.svd(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the output of first layer with following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first layer output:  (8, 4)\n"
     ]
    }
   ],
   "source": [
    "t = K.function([model.layers[0].input], [model.layers[0].output])([np.eye(input_size)])[0]\n",
    "t_mean = np.matmul(Px.reshape(1, -1), t)\n",
    "print(\"Shape of the first layer output: \", t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi1 = t*(np.sqrt(Px).reshape(-1,1))  # information matrix input\n",
    "Phi1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, verbose=0, batch_size=5000, epochs=200)\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.get_weights()[4].T\n",
    "Phi2 = v*(np.sqrt(Py).reshape(-1,1))  # information matrix output\n",
    "b = model.get_weights()[5]\n",
    "b_hat = b - np.dot(b, Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the output of second layer with following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = K.function([model.layers[0].input], [model.layers[1].output])([np.eye(input_size)])[0]\n",
    "s_mean = np.matmul(Px.reshape(1, -1), s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_theory = np.log(Py) - np.matmul(v, s_mean.T).reshape(-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_hidden' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-66c0b5d517ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc_theory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_hidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'P_hidden' is not defined"
     ]
    }
   ],
   "source": [
    "c = model.get_weights()[3]  \n",
    "c = normalize(c)\n",
    "w = model.get_weights()[2]\n",
    "c_theory = np.log(P_hidden) - np.matmul(w, t_mean.T).reshape(-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here c is the biad of the training and c_theory is the biad os the theoretical part.\n",
    "Unfortunately I do not know how to calculate the distribution of the second hidden layer. For doing this I need read more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
